{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from sklearn import metrics\n",
    "import statsmodels\n",
    "from statsmodels.graphics.tsaplots import plot_acf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data uploading\n",
    "\n",
    "The data was generated form the AR(1) model of the following form $y_t=N(0,1)-0.6y_{t-1}$\n",
    "\n",
    "Size of the data set: t=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d1=pd.read_csv(\"AR.csv\")\n",
    "data=np.array(d1.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_acf(data, lags=31)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "Arguments: \n",
    "\n",
    "-time_wind: length of the sequence of the historical data;\n",
    "\n",
    "-output: how many steps ahead prediction is going to be performed;\n",
    "\n",
    "-nb_var: number of variables of the data set;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_preparation(data,time_wind=2,output=1,nb_var=1,batch_size=1):\n",
    "    data_train=data[:901]\n",
    "    x_train=[]\n",
    "    for i in range((len(data_train)-1)-(time_wind-1)):\n",
    "        x_train.append(data_train[i:(i+time_wind)])\n",
    "    x_train=np.array(x_train)\n",
    "    x_batches=(x_train[:(len(x_train)-(len(x_train)%batch_size))]).reshape(-1,time_wind,nb_var)\n",
    "    y_train=data_train[time_wind:len(data_train)]\n",
    "    y_batches=(y_train[:(len(y_train)-(len(y_train)%batch_size))]).reshape(-1,output)\n",
    "    data_test=data[902:]\n",
    "    x_t=[]\n",
    "    for i in range((len(data_test)-1)-(time_wind-1)):\n",
    "        x_t.append(data_test[i:(i+time_wind)])\n",
    "    x_t=np.array(x_t)\n",
    "    x_test=(x_t[:(len(x_t)-(len(x_t)%batch_size))]).reshape(-1,time_wind,nb_var)\n",
    "    y_t=data_test[time_wind:len(data_test)]\n",
    "    y_test=(y_t[:(len(y_t)-(len(y_t)%batch_size))]).reshape(-1,output)\n",
    "    return x_batches, y_batches, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow graph\n",
    "\n",
    "Arguments:\n",
    "\n",
    "-epochs: how many times the network is going to be trained;\n",
    "\n",
    "-time_wind: the length of the historical sequence;\n",
    "\n",
    "-hidden: number of hidden layers;\n",
    "\n",
    "-nb_var: amount of input variables;\n",
    "\n",
    "-output: how many steps ahead prediction is going to be performed;\n",
    "\n",
    "-lr: learning rate.\n",
    "\n",
    "Outputs:\n",
    "\n",
    "-mse_test: the mean squared error for the final prediction vector;\n",
    "\n",
    "-y_pred: the vector of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_graph(epochs,time_wind,hidden=10,nb_var=1,output=1,lr=0.01,r_s=1):\n",
    "\n",
    "    from tensorflow.contrib import rnn\n",
    "    tf.reset_default_graph()\n",
    "    X=tf.placeholder(tf.float32,[None,time_wind,nb_var])\n",
    "    Y=tf.placeholder(tf.float32,[None,output])\n",
    " \n",
    "    tf.set_random_seed(r_s)\n",
    "    x=tf.unstack(X,time_wind,1)\n",
    "    \n",
    "    basic_cell=tf.contrib.rnn.BasicRNNCell(num_units=hidden)\n",
    "    rnn_output, states=rnn.static_rnn(basic_cell,x,dtype=tf.float32)\n",
    "\n",
    "    stacked_rnn_output=tf.reshape(rnn_output[-1],[-1,hidden])\n",
    "    stacked_outputs=tf.layers.dense(stacked_rnn_output,output)\n",
    "    loss=tf.reduce_mean(tf.squared_difference(stacked_outputs, Y))\n",
    "    optimizer=tf.train.AdamOptimizer(learning_rate=lr)\n",
    "    training_op=optimizer.minimize(loss)\n",
    "    init=tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        init.run()\n",
    "        for ep in range(epochs):\n",
    "            sess.run(training_op,feed_dict={X: x_batches, Y: y_batches})\n",
    "            if ep % 1000 == 0:\n",
    "                mse=loss.eval(feed_dict={X: x_batches, Y: y_batches})\n",
    "                print(ep,\"\\tMSE:\",mse)\n",
    "        y_pred=sess.run(stacked_outputs,feed_dict={X:x_test})\n",
    "        mse_test=loss.eval(feed_dict={X:x_test,Y:y_test})\n",
    "        print(mse)\n",
    "        print(mse_test)\n",
    "    sess.close() \n",
    "    return mse_test, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualisation():\n",
    "    plt.plot(y_test,label='Actual')\n",
    "    plt.plot(y_pred,label='Forecast')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    return plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expariments\n",
    "## Naive models\n",
    "### Average naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_batches, y_batches, x_test, y_test=data_preparation(data,1)\n",
    "print(metrics.mean_squared_error(x_batches[:,0],np.full(len(x_batches),np.mean(x_batches))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_t1=y_test[:96]\n",
    "x_t=y_test[1:]\n",
    "print(metrics.mean_squared_error(x_t,x_t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time_wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mse_mean=[]\n",
    "mse_var=[]\n",
    "for j in range(1,9,1):\n",
    "    mse=[]\n",
    "    for i in range (10):\n",
    "        x_batches, y_batches, x_test, y_test=data_preparation(data,j)\n",
    "        mse_test,y_pred=run_graph(1000,j,hidden=1,lr=0.1,r_s=i)\n",
    "        mse.append(mse_test)\n",
    "    mse_mean.append(np.mean(mse))\n",
    "    mse_var.append(np.var(mse))\n",
    "    print(\"Mean of MSE for the model with time_wind={} equals{}\".format(j, np.mean(mse)))\n",
    "    print(\"Variance of MSE for the model with time_wind={} equals{}\".format(j, np.var(mse)))\n",
    "visualisation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(mse_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary: it is no need to widen the time window. What is according to our expectations (as the data was generated form the process AR(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_mean=[]\n",
    "mse_var=[]\n",
    "for j in range(1,11,1):\n",
    "    mse=[]\n",
    "    for i in range (10):\n",
    "        x_batches, y_batches, x_test, y_test=data_preparation(data,1)\n",
    "        mse_test,y_pred=run_graph(1000,1,hidden=j,lr=0.1,r_s=i)\n",
    "        mse.append(mse_test)\n",
    "    mse_mean.append(np.mean(mse))\n",
    "    mse_var.append(np.var(mse))\n",
    "    print(\"Mean of MSE for the model with hidden={} equals{}\".format(j, np.mean(mse)))\n",
    "    print(\"Variance of MSE for the model with hidden={} equals{}\".format(j, np.var(mse)))\n",
    "visualisation()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(mse_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary: The best accuracy is achieved with the hidden=10. MSE=1.004931. As hidden=10 was the last value that was tested during the experiment, it makes sense to perform one more, in order to check the next range of sizes of the hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_mean=[]\n",
    "mse_var=[]\n",
    "for j in range(10,31,1):\n",
    "    mse=[]\n",
    "    for i in range (10):\n",
    "        x_batches, y_batches, x_test, y_test=data_preparation(data,1)\n",
    "        mse_test,y_pred=run_graph(1000,1,hidden=j,lr=0.1,r_s=i)\n",
    "        mse.append(mse_test)\n",
    "    mse_mean.append(np.mean(mse))\n",
    "    mse_var.append(np.var(mse))\n",
    "    print(\"Mean of MSE for the model with hidden={} equals{}\".format(j, np.mean(mse)))\n",
    "    print(\"Variance of MSE for the model with hidden={} equals{}\".format(j, np.var(mse)))\n",
    "visualisation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(mse_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Summary: The highest accuracy is achieved with size of the hidden state equal to hidden=18. MSE=1.0048877"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimisation of the training time\n",
    "## Learning rate: 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mse_mean=[]\n",
    "mse_var=[]\n",
    "for j in range(1000,11000,1000):\n",
    "    mse=[]\n",
    "    for i in range (10):\n",
    "        x_batches, y_batches, x_test, y_test=data_preparation(data,1)\n",
    "        mse_test,y_pred=run_graph(j,1,hidden=18,lr=0.1,r_s=i)\n",
    "        mse.append(mse_test)\n",
    "    mse_mean.append(np.mean(mse))\n",
    "    mse_var.append(np.var(mse))\n",
    "    print(\"Mean of MSE for the model with epochs={} equals {}\".format(j, np.mean(mse)))\n",
    "    print(\"Variance of MSE for the model with epochs={} equals {}\".format(j, np.var(mse)))\n",
    "visualisation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(mse_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary:  With the learning rate equal to 0.01, the highest accuracy is achieved with the number of epochs equal to 5000. The MSE=0.99077922"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate: 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_mean=[]\n",
    "mse_var=[]\n",
    "for j in range(3000,11000,1000):\n",
    "    mse=[]\n",
    "    for i in range (10):\n",
    "        x_batches, y_batches, x_test, y_test=data_preparation(data,1)\n",
    "        mse_test,y_pred=run_graph(j,1,hidden=18,lr=0.01,r_s=i)\n",
    "        mse.append(mse_test)\n",
    "    mse_mean.append(np.mean(mse))\n",
    "    mse_var.append(np.var(mse))\n",
    "    print(\"Mean of MSE for the model with epochs={} equals {}\".format(j, np.mean(mse)))\n",
    "    print(\"Variance of MSE for the model with epochs={} equals {}\".format(j, np.var(mse)))\n",
    "visualisation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(mse_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary: With the lr=0.01, the lowest MSE is echieved with number of training epochs equal to 8000. MSE= 0.98785669"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate: 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_mean=[]\n",
    "mse_var=[]\n",
    "for j in range(6000,14000,1000):\n",
    "    mse=[]\n",
    "    for i in range (10):\n",
    "        x_batches, y_batches, x_test, y_test=data_preparation(data,1)\n",
    "        mse_test,y_pred=run_graph(j,1,hidden=18,lr=0.001,r_s=i)\n",
    "        mse.append(mse_test)\n",
    "    mse_mean.append(np.mean(mse))\n",
    "    mse_var.append(np.var(mse))\n",
    "    print(\"Mean of MSE for the model with epochs={} equals {}\".format(j, np.mean(mse)))\n",
    "    print(\"Variance of MSE for the model with epochs={} equals {}\".format(j, np.var(mse)))\n",
    "visualisation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(mse_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary: The highest accuracy is achived with the number of training epochs 14000. MSE=0.99555.  However, looking on the  dynamic of the changes of the accuracy, we get the conclusion that experiment should be continuing on the following range of the training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_mean=[]\n",
    "mse_var=[]\n",
    "for j in range(14000,22000,1000):\n",
    "    mse=[]\n",
    "    for i in range (10):\n",
    "        x_batches, y_batches, x_test, y_test=data_preparation(data,1)\n",
    "        mse_test,y_pred=run_graph(j,1,hidden=18,lr=0.001,r_s=i)\n",
    "        mse.append(mse_test)\n",
    "    mse_mean.append(np.mean(mse))\n",
    "    mse_var.append(np.var(mse))\n",
    "    print(\"Mean of MSE for the model with epochs={} equals {}\".format(j, np.mean(mse)))\n",
    "    print(\"Variance of MSE for the model with epochs={} equals {}\".format(j, np.var(mse)))\n",
    "visualisation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(mse_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Summary: the highest accuracy is achieved with number of epochs equal to 19000. MSE=0.98768318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
