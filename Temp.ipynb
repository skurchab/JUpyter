{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of the data set\n",
    "\n",
    "Real world data\n",
    "\n",
    "Data source: Temp.csv\n",
    "\n",
    "# One to one prediction\n",
    "\n",
    "V1 column for 1 to 1 prediction. Shape: (1625,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d1=pd.read_csv(\"Temp.csv\")\n",
    "data=np.array(d1.V1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "Arguments:\n",
    "\n",
    "-time_wind: length of the sequence of the historical data;\n",
    "\n",
    "-output: how many steps ahead prediction is going to be performed;\n",
    "\n",
    "-nb_var: number of variables of the data set;\n",
    "\n",
    "Output:\n",
    "\n",
    "-x_batches: input for the training set. Size: (1518, 2, 1);\n",
    "\n",
    "-y_batches: output for the training set. Size: (1518, 1);\n",
    "\n",
    "-x_test: inputs for the test set; Size: (102, 2, 1);\n",
    "\n",
    "-y_test: output for the test set; Size: (102, 1);\n",
    "\n",
    "! Note, the size of the first dimension will vary depending on the size of the time_wind. The second dimension refers to the time_wind size, thisrd dimension: number of variables;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_preparation(data,time_wind=2,output=1,nb_var=1,batch_size=1):\n",
    "    data_train=data[:1520]\n",
    "    x_train=[]\n",
    "    for i in range((len(data_train)-1)-(time_wind-1)):\n",
    "        x_train.append(data_train[i:(i+time_wind)])\n",
    "    x_train=np.array(x_train)\n",
    "    x_batches=(x_train[:(len(x_train)-(len(x_train)%batch_size))]).reshape(-1,time_wind,nb_var)\n",
    "    y_train=data_train[time_wind:len(data_train)]\n",
    "    y_batches=(y_train[:(len(y_train)-(len(y_train)%batch_size))]).reshape(-1,output)\n",
    "    data_test=data[1521:]\n",
    "    x_t=[]\n",
    "    for i in range((len(data_test)-1)-(time_wind-1)):\n",
    "        x_t.append(data_test[i:(i+time_wind)])\n",
    "    x_t=np.array(x_t)\n",
    "    x_test=(x_t[:(len(x_t)-(len(x_t)%batch_size))]).reshape(-1,time_wind,nb_var)\n",
    "    y_t=data_test[time_wind:len(data_test)]\n",
    "    y_test=(y_t[:(len(y_t)-(len(y_t)%batch_size))]).reshape(-1,output)\n",
    "    return x_batches, y_batches, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow computation graph\n",
    "\n",
    "Arguments:\n",
    "\n",
    "-epochs: how many times the network is going to be trained;\n",
    "\n",
    "-time_wind: the length of the historical sequence;\n",
    "\n",
    "-hidden: number of hidden layers;\n",
    "\n",
    "-nb_var: amount of input variables;\n",
    "\n",
    "-output: how many steps ahead prediction is going to be performed;\n",
    "\n",
    "-lr: learning rate.\n",
    "\n",
    "Outputs:\n",
    "\n",
    "-mse_test: the mean squared error for the final prediction vector;\n",
    "\n",
    "-y_pred: the vector of predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_graph(epochs,time_wind,hidden=10,nb_var=1,output=1,lr=0.01,r_s=1):\n",
    "\n",
    "    from tensorflow.contrib import rnn\n",
    "    tf.reset_default_graph()\n",
    "    X=tf.placeholder(tf.float32,[None,time_wind,nb_var])\n",
    "    Y=tf.placeholder(tf.float32,[None,output])\n",
    " \n",
    "    tf.set_random_seed(r_s)\n",
    "    x=tf.unstack(X,time_wind,1)\n",
    "    \n",
    "    basic_cell=tf.contrib.rnn.BasicRNNCell(num_units=hidden)\n",
    "    rnn_output, states=rnn.static_rnn(basic_cell,x,dtype=tf.float32)\n",
    "\n",
    "    stacked_rnn_output=tf.reshape(rnn_output[-1],[-1,hidden])\n",
    "    stacked_outputs=tf.layers.dense(stacked_rnn_output,output)\n",
    "    loss=tf.reduce_mean(tf.squared_difference(stacked_outputs, Y))\n",
    "    optimizer=tf.train.AdamOptimizer(learning_rate=lr)\n",
    "    training_op=optimizer.minimize(loss)\n",
    "    init=tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        init.run()\n",
    "        for ep in range(epochs):\n",
    "            sess.run(training_op,feed_dict={X: x_batches, Y: y_batches})\n",
    "            if ep % 100 == 0:\n",
    "                mse=loss.eval(feed_dict={X: x_batches, Y: y_batches})\n",
    "                print(ep,\"\\tMSE:\",mse)\n",
    "        y_pred=sess.run(stacked_outputs,feed_dict={X:x_test})\n",
    "        mse_test=loss.eval(feed_dict={X:x_test,Y:y_test})\n",
    "        print(mse)\n",
    "        print(mse_test)\n",
    "    sess.close() \n",
    "    return mse_test, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualisation():\n",
    "    plt.plot(y_test,label='Actual')\n",
    "    plt.plot(y_pred,label='Forecast')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    return plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive models\n",
    "### Average naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_batches, y_batches, x_test, y_test=data_preparation(data,1)\n",
    "print(metrics.mean_squared_error(x_batches[:,0],np.full(len(x_batches),np.mean(x_batches))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant naive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_t1=y_test[:102]\n",
    "x_t=y_test[1:]\n",
    "print(metrics.mean_squared_error(x_t,x_t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time_wind\n",
    "The aim of the first  experiment is to define the optimal size of the time_wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mse_mean=[]\n",
    "mse_var=[]\n",
    "for j in range(1,9,1):\n",
    "    mse=[]\n",
    "    for i in range (10):\n",
    "        x_batches, y_batches, x_test, y_test=data_preparation(data,j)\n",
    "        mse_test,y_pred=run_graph(1000,j,hidden=1,lr=0.1,r_s=i)\n",
    "        mse.append(mse_test)\n",
    "    mse_mean.append(np.mean(mse))\n",
    "    mse_var.append(np.var(mse))\n",
    "    print(\"Mean of MSE for the model with time_wind={} equals{}\".format(j, np.mean(mse)))\n",
    "    print(\"Variance of MSE for the model with time_wind={} equals{}\".format(j, np.var(mse)))\n",
    "visualisation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(mse_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary: the highest accuracy was achieved with time_wind=2. Then MSE=8.106884. \n",
    "The accuracy of the basic model with time_wind=1 is equal to 15.629408, what is better the the results of the naive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden layers\n",
    "The aim of the second experiment is to discover wether the increment of the number of hidden layers will improve the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mse_mean=[]\n",
    "mse_var=[]\n",
    "for j in range(1,11,1):\n",
    "    mse=[]\n",
    "    for i in range (10):\n",
    "        x_batches, y_batches, x_test, y_test=data_preparation(data,2)\n",
    "        mse_test,y_pred=run_graph(1000,2,hidden=j,lr=0.1,r_s=i)\n",
    "        mse.append(mse_test)\n",
    "    mse_mean.append(np.mean(mse))\n",
    "    mse_var.append(np.var(mse))\n",
    "    print(\"Mean of MSE for the model with hidden={} equals{}\".format(j, np.mean(mse)))\n",
    "    print(\"Variance of MSE for the model with hidden={} equals{}\".format(j, np.var(mse)))\n",
    "visualisation()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(mse_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary: The lowest MSE is achieved with hidden=6. MSE=5.53754. \n",
    "The structure of the data is too complex to hadle it with the smaller size of hidden states, however, the bigger amount of hiddent units cause overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimisation of the training time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate: 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mse_mean=[]\n",
    "mse_var=[]\n",
    "for j in range(1000,11000,1000):\n",
    "    mse=[]\n",
    "    for i in range (10):\n",
    "        x_batches, y_batches, x_test, y_test=data_preparation(data,2)\n",
    "        mse_test,y_pred=run_graph(j,2,hidden=6,lr=0.1,r_s=i)\n",
    "        mse.append(mse_test)\n",
    "    mse_mean.append(np.mean(mse))\n",
    "    mse_var.append(np.var(mse))\n",
    "    print(\"Mean of MSE for the model with epochs={} equals {}\".format(j, np.mean(mse)))\n",
    "    print(\"Variance of MSE for the model with epochs={} equals {}\".format(j, np.var(mse)))\n",
    "visualisation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(mse_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary:\n",
    "With the learning rate equal to 0.01, increasing of the training time does not improve the quality of predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate: 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mse_mean=[]\n",
    "mse_var=[]\n",
    "for j in range(2000,11000,1000):\n",
    "    mse=[]\n",
    "    for i in range (10):\n",
    "        x_batches, y_batches, x_test, y_test=data_preparation(data,2)\n",
    "        mse_test,y_pred=run_graph(j,2,hidden=6,lr=0.01,r_s=i)\n",
    "        mse.append(mse_test)\n",
    "    mse_mean.append(np.mean(mse))\n",
    "    mse_var.append(np.var(mse))\n",
    "    print(\"Mean of MSE for the model with epochs={} equals {}\".format(j, np.mean(mse)))\n",
    "    print(\"Variance of MSE for the model with epochs={} equals {}\".format(j, np.var(mse)))\n",
    "visualisation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(mse_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary:  With learning rate equal to 0.01, the highest accuracy was achieved with number of training epochs equal to 3000. Then, MSE=5.66024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate: 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_mean=[]\n",
    "mse_var=[]\n",
    "for j in range(4000,17000,1000):\n",
    "    mse=[]\n",
    "    for i in range (10):\n",
    "        x_batches, y_batches, x_test, y_test=data_preparation(data,2)\n",
    "        mse_test,y_pred=run_graph(j,2,hidden=6,lr=0.001,r_s=i)\n",
    "        mse.append(mse_test)\n",
    "    mse_mean.append(np.mean(mse))\n",
    "    mse_var.append(np.var(mse))\n",
    "    print(\"Mean of MSE for the model with epochs={} equals {}\".format(j, np.mean(mse)))\n",
    "    print(\"Variance of MSE for the model with epochs={} equals {}\".format(j, np.var(mse)))\n",
    "visualisation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(mse_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary: with the learnig rate equal to 0.001, the lowes MSE was achieved with number of epoch equal to 9000. MSE=5.69389"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Many to one prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V1, V2 columns for 2 to 1 prediction. Shape: (2,1625)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2=np.array([d1.V1,d1.V2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_preparation2(data,time_wind=2,output=1,nb_var=2,batch_size=1):\n",
    "    data_train=data[:1520]\n",
    "    x_train=[]\n",
    "    for i in range((len(data_train)-1)-(time_wind-1)):\n",
    "        x_train.append(data_train[i:(i+time_wind)])\n",
    "    x_train=np.array(x_train)\n",
    "    x_batches=(x_train[:(len(x_train)-(len(x_train)%batch_size))]).reshape(-1,time_wind,nb_var)\n",
    "    y_train=data_train[time_wind:len(data_train)]\n",
    "    y_batches=(y_train[:,0][:(len(y_train)-(len(y_train)%batch_size))]).reshape(-1,output)\n",
    "    data_test=data[1521:]\n",
    "    x_t=[]\n",
    "    for i in range((len(data_test)-1)-(time_wind-1)):\n",
    "        x_t.append(data_test[i:(i+time_wind)])\n",
    "    x_t=np.array(x_t)\n",
    "    x_test=(x_t[:(len(x_t)-(len(x_t)%batch_size))]).reshape(-1,time_wind,nb_var)\n",
    "    y_t=data_test[time_wind:len(data_test)]\n",
    "    y_test=(y_t[:,0][:(len(y_t)-(len(y_t)%batch_size))]).reshape(-1,output)\n",
    "    return x_batches, y_batches, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time_wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_mean=[]\n",
    "mse_var=[]\n",
    "for j in range(1,9,1):\n",
    "    mse=[]\n",
    "    for i in range (10):\n",
    "        x_batches, y_batches, x_test, y_test=data_preparation2(data2.T,j,nb_var=2)\n",
    "        mse_test,y_pred=run_graph(1000,j,hidden=1,lr=0.1,r_s=i,nb_var=2)\n",
    "        mse.append(mse_test)\n",
    "    mse_mean.append(np.mean(mse))\n",
    "    mse_var.append(np.var(mse))\n",
    "    print(\"Mean of MSE for the model with time_wind={} equals{}\".format(j, np.mean(mse)))\n",
    "    print(\"Variance of MSE for the model with time_wind={} equals{}\".format(j, np.var(mse)))\n",
    "visualisation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(mse_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary: The lowest MSE was achieved with the time window of size 2 (time_wind=2). MSE=6.4604"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_mean=[]\n",
    "mse_var=[]\n",
    "for j in range(1,11,1):\n",
    "    mse=[]\n",
    "    for i in range (10):\n",
    "        x_batches, y_batches, x_test, y_test=data_preparation2(data2.T,2,nb_var=2)\n",
    "        mse_test,y_pred=run_graph(1000,2,hidden=j,lr=0.1,r_s=i,nb_var=2)\n",
    "        mse.append(mse_test)\n",
    "    mse_mean.append(np.mean(mse))\n",
    "    mse_var.append(np.var(mse))\n",
    "    print(\"Mean of MSE for the model with hidden={} equals{}\".format(j, np.mean(mse)))\n",
    "    print(\"Variance of MSE for the model with hidden={} equals{}\".format(j, np.var(mse)))\n",
    "visualisation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(mse_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary: the highest accuracy was achieved with the hidden state size equal to hidden=5. MSE=4.64192"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimisation of the training time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate: 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_mean=[]\n",
    "mse_var=[]\n",
    "for j in range(1000,11000,1000):\n",
    "    mse=[]\n",
    "    for i in range (10):\n",
    "        x_batches, y_batches, x_test, y_test=data_preparation2(data2.T,2,nb_var=2)\n",
    "        mse_test,y_pred=run_graph(j,2,hidden=5,lr=0.1,r_s=i,nb_var=2)\n",
    "        mse.append(mse_test)\n",
    "    mse_mean.append(np.mean(mse))\n",
    "    mse_var.append(np.var(mse))\n",
    "    print(\"Mean of MSE for the model with epochs={} equals {}\".format(j, np.mean(mse)))\n",
    "    print(\"Variance of MSE for the model with epochs={} equals {}\".format(j, np.var(mse)))\n",
    "visualisation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(mse_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary: with the learning rate equal to 0.1, the increment of the training time does not inprove the accuracy of the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate: 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_mean=[]\n",
    "mse_var=[]\n",
    "for j in range(1000,11000,1000):\n",
    "    mse=[]\n",
    "    for i in range (10):\n",
    "        x_batches, y_batches, x_test, y_test=data_preparation2(data2.T,2,nb_var=2)\n",
    "        mse_test,y_pred=run_graph(j,2,hidden=5,lr=0.01,r_s=i,nb_var=2)\n",
    "        mse.append(mse_test)\n",
    "    mse_mean.append(np.mean(mse))\n",
    "    mse_var.append(np.var(mse))\n",
    "    print(\"Mean of MSE for the model with epochs={} equals {}\".format(j, np.mean(mse)))\n",
    "    print(\"Variance of MSE for the model with epochs={} equals {}\".format(j, np.var(mse)))\n",
    "visualisation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(mse_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary: With the learning rate equal to 0.01 the highest accuracy was achieved with number of epochs=4000. MSE=4.37898"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate: 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_mean=[]\n",
    "mse_var=[]\n",
    "for j in range(4000,15000,1000):\n",
    "    mse=[]\n",
    "    for i in range (10):\n",
    "        x_batches, y_batches, x_test, y_test=data_preparation2(data2.T,2,nb_var=2)\n",
    "        mse_test,y_pred=run_graph(j,2,hidden=5,lr=0.001,r_s=i,nb_var=2)\n",
    "        mse.append(mse_test)\n",
    "    mse_mean.append(np.mean(mse))\n",
    "    mse_var.append(np.var(mse))\n",
    "    print(\"Mean of MSE for the model with epochs={} equals {}\".format(j, np.mean(mse)))\n",
    "    print(\"Variance of MSE for the model with epochs={} equals {}\".format(j, np.var(mse)))\n",
    "visualisation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(mse_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary: with the learning rate 0.001, the highest accuracy is achieved with number of epochs=10000. MSE=4.38957"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
